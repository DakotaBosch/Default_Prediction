{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.impute import SimpleImputer\nfrom sklearn import metrics\nimport gc\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-08-24T17:07:02.984789Z","iopub.execute_input":"2022-08-24T17:07:02.985614Z","iopub.status.idle":"2022-08-24T17:07:02.998187Z","shell.execute_reply.started":"2022-08-24T17:07:02.985557Z","shell.execute_reply":"2022-08-24T17:07:02.997087Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"/kaggle/input/amex-default-prediction/sample_submission.csv\n/kaggle/input/amex-default-prediction/train_data.csv\n/kaggle/input/amex-default-prediction/test_data.csv\n/kaggle/input/amex-default-prediction/train_labels.csv\n/kaggle/input/amex-parquet/test_data.parquet\n/kaggle/input/amex-parquet/train_data.parquet\n","output_type":"stream"}]},{"cell_type":"code","source":"df1=pd.read_parquet('/kaggle/input/amex-parquet/train_data.parquet')\ndf1.head()\ndf1.shape\ndf_label = pd.read_csv('/kaggle/input/amex-default-prediction/train_labels.csv')\ndf_label.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-24T17:07:03.000120Z","iopub.execute_input":"2022-08-24T17:07:03.001456Z","iopub.status.idle":"2022-08-24T17:07:37.099596Z","shell.execute_reply.started":"2022-08-24T17:07:03.001397Z","shell.execute_reply":"2022-08-24T17:07:37.094155Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3552, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/tmp/ipykernel_17/3445842997.py\", line 1, in <module>\n    df1=pd.read_parquet('/kaggle/input/amex-parquet/train_data.parquet')\n  File \"/opt/conda/lib/python3.7/site-packages/pandas/io/parquet.py\", line 500, in read_parquet\n    **kwargs,\n  File \"/opt/conda/lib/python3.7/site-packages/pandas/io/parquet.py\", line 240, in read\n    path_or_handle, columns=columns, **kwargs\n  File \"/opt/conda/lib/python3.7/site-packages/pyarrow/parquet/__init__.py\", line 2781, in read_table\n    use_pandas_metadata=use_pandas_metadata)\n  File \"/opt/conda/lib/python3.7/site-packages/pyarrow/parquet/__init__.py\", line 2445, in read\n    use_threads=use_threads\nKeyboardInterrupt\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2098, in showtraceback\n    stb = value._render_traceback_()\nAttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n    return f(*args, **kwargs)\n  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n  File \"/opt/conda/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n  File \"/opt/conda/lib/python3.7/inspect.py\", line 1464, in getframeinfo\n    lines, lnum = findsource(frame)\n  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 182, in findsource\n    lines = linecache.getlines(file, globals_dict)\n  File \"/opt/conda/lib/python3.7/linecache.py\", line 47, in getlines\n    return updatecache(filename, module_globals)\n  File \"/opt/conda/lib/python3.7/linecache.py\", line 137, in updatecache\n    lines = fp.readlines()\n  File \"/opt/conda/lib/python3.7/codecs.py\", line 319, in decode\n    def decode(self, input, final=False):\nKeyboardInterrupt\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_17/3445842997.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/kaggle/input/amex-parquet/train_data.parquet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, **kwargs)\u001b[0m\n\u001b[1;32m    499\u001b[0m         \u001b[0muse_nullable_dtypes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_nullable_dtypes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    501\u001b[0m     )\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, path, columns, use_nullable_dtypes, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m    239\u001b[0m             result = self.api.parquet.read_table(\n\u001b[0;32m--> 240\u001b[0;31m                 \u001b[0mpath_or_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m             ).to_pandas(**to_pandas_kwargs)\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pyarrow/parquet/__init__.py\u001b[0m in \u001b[0;36mread_table\u001b[0;34m(source, columns, use_threads, metadata, schema, use_pandas_metadata, memory_map, read_dictionary, filesystem, filters, buffer_size, partitioning, use_legacy_dataset, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, decryption_properties)\u001b[0m\n\u001b[1;32m   2780\u001b[0m         return dataset.read(columns=columns, use_threads=use_threads,\n\u001b[0;32m-> 2781\u001b[0;31m                             use_pandas_metadata=use_pandas_metadata)\n\u001b[0m\u001b[1;32m   2782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pyarrow/parquet/__init__.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, columns, use_threads, use_pandas_metadata)\u001b[0m\n\u001b[1;32m   2444\u001b[0m             \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filter_expression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2445\u001b[0;31m             \u001b[0muse_threads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_threads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2446\u001b[0m         )\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: ","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2097\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2098\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2099\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2099\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 2101\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   2102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2103\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1368\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1268\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m             )\n\u001b[1;32m   1270\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Minimal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m-> 1125\u001b[0;31m                                                                tb_offset)\n\u001b[0m\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m         \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColors\u001b[0m  \u001b[0;31m# just a shorthand + quicker name lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"],"ename":"TypeError","evalue":"object of type 'NoneType' has no len()","output_type":"error"}]},{"cell_type":"code","source":"df1.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-24T17:07:37.100670Z","iopub.status.idle":"2022-08-24T17:07:37.101458Z","shell.execute_reply.started":"2022-08-24T17:07:37.101197Z","shell.execute_reply":"2022-08-24T17:07:37.101220Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking out data types\nprint(df1.dtypes.value_counts())\nlist(df1.select_dtypes(['object']).columns)","metadata":{"execution":{"iopub.status.busy":"2022-08-24T17:07:37.103021Z","iopub.status.idle":"2022-08-24T17:07:37.103470Z","shell.execute_reply.started":"2022-08-24T17:07:37.103238Z","shell.execute_reply":"2022-08-24T17:07:37.103290Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#visualizing columns\n\n#hist = df1.hist(bins=10, figsize = (40,200), layout=(-1,4) )","metadata":{"execution":{"iopub.status.busy":"2022-08-24T17:07:37.105038Z","iopub.status.idle":"2022-08-24T17:07:37.105899Z","shell.execute_reply.started":"2022-08-24T17:07:37.105691Z","shell.execute_reply":"2022-08-24T17:07:37.105712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df1.shape[1])\n#inspecting NaN\nfor i in range(len(df1.columns)):\n    if (df1.iloc[:,i].isnull().sum()/len(df1) > 0.1):\n        print(df1.columns[i], round(df1.iloc[:,i].isnull().sum()/len(df1),2))\n\n#drop columns with high freq of NaN\ncolumns_to_drop = [column for column in df1.columns if df1[column].isnull().sum()/len(df1) >= 0.1]\ndf1.drop(columns_to_drop, axis=1, inplace=True)\nprint(df1.shape[1])","metadata":{"execution":{"iopub.status.busy":"2022-08-24T17:07:37.107121Z","iopub.status.idle":"2022-08-24T17:07:37.108156Z","shell.execute_reply.started":"2022-08-24T17:07:37.107807Z","shell.execute_reply":"2022-08-24T17:07:37.107838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#using only most recent transaction from each customer\ntemp = df1.shape\ndf1=df1.set_index(['customer_ID'])\ndf1=df1.ffill()\ndf1=df1.bfill()\ndf1=df1.reset_index()\n\ndf1=df1.groupby('customer_ID').tail(1)\ndf1=df1.set_index(['customer_ID'])\n\n#Drop date column since it is no longer useful\ndf1.drop(['S_2'],axis=1,inplace=True)\n\nprint(temp, df1.shape)\n\n#inspecting NaN\nfor i in range(len(df1.columns)):\n    print('Columns left with NaN:')\n    if (df1.iloc[:,i].isnull().sum()/len(df1) > 0):\n        print(df1.columns[i], round(df1.iloc[:,i].isnull().sum()/len(df1),2))","metadata":{"execution":{"iopub.status.busy":"2022-08-24T17:07:37.110115Z","iopub.status.idle":"2022-08-24T17:07:37.111150Z","shell.execute_reply.started":"2022-08-24T17:07:37.110804Z","shell.execute_reply":"2022-08-24T17:07:37.110836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1.head()\ndf1 = df1.drop(['target'], axis=1)\nkeep = df1.columns","metadata":{"execution":{"iopub.status.busy":"2022-08-24T17:07:37.113290Z","iopub.status.idle":"2022-08-24T17:07:37.113910Z","shell.execute_reply.started":"2022-08-24T17:07:37.113595Z","shell.execute_reply":"2022-08-24T17:07:37.113624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df1.shape)\n# Create correlation matrix\ncorr_matrix = df1.corr().abs()\n\n# Select upper triangle of correlation matrix\nupper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n\n# Find features with correlation greater than 0.9\nto_drop = [column for column in upper.columns if any(upper[column] > 0.9)]\n\n# Drop features w/ high correl\ndf1.drop(to_drop, axis=1, inplace=True)\n\nprint(df1.shape)\n","metadata":{"execution":{"iopub.status.busy":"2022-08-24T17:07:37.115571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Removing low variance columns in interest of ram\nfrom sklearn.feature_selection import VarianceThreshold\nfrom itertools import compress\n\ntemp = df1.drop(['D_63', 'D_64'], axis=1)\n\n# Initialize and fit the method\nvt = VarianceThreshold(threshold = float(0.1))\nvt.fit(temp)\n\n#columns with sufficient variance\nkeep = list(compress(temp.columns, vt.get_support()))\n\nkeep.append('D_63')\nkeep.append('D_64')\n\ndf1=df1[keep]\nlen(keep)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#removing outliers\n##print(df1.shape)\n\n#df1 = df1[df1['R_6'] < df1['R_6'].quantile(0.97)]\n#print(df1['R_6'].max())\n#print(df1.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#df1.iloc[:100000,7].value_counts()\n#print(df1.iloc[:,1].head())\n\n\n#What type of variable for dates\n#df1['S_2'] = pd.to_datetime(df1['S_2'])\n#df1['S_2'] = pd.to_numeric(df1['S_2'])\n\n#normalizing\n#df1['S_2'] = (df1['S_2']-df1['S_2'].min())/(df1['S_2'].max() - df1['S_2'].min())\n#print(df1['S_2'].head())\n\n#df1['S_2'] = pd.to_timedelta(df1['S_2'])\n#print(df1.iloc[:,1].dt.total_seconds())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Hot ones\ndf1 = pd.get_dummies(df1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Handling missing values\n#my_imputer = SimpleImputer()\n#df1.iloc[:,:] = my_imputer.fit_transform(df1.iloc[:,:])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df1.iloc[:, :].values.reshape(-1, len(df1.columns))\nY = df_label.iloc[:len(df1), 1].values.reshape(-1, 1)\nprint('half')\n# create object for the class\nlog = LogisticRegression()\nlog.fit(X, Y) \nY_pred = log.predict(X)\n\nprint(Y_pred, np.sum(Y_pred))\nprint(log.score(X, Y))\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm = metrics.confusion_matrix(Y, Y_pred)\n\nplt.figure(figsize=(9,9))\nsns.heatmap(cm, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'YlGnBu');\nplt.ylabel('Actual label');\nplt.xlabel('Predicted label');\nall_sample_title = 'Accuracy Score: {0}'.format(round(log.score(X, Y),3))\nplt.title(all_sample_title, size = 15);\n\nprint('Accuracy:',round(metrics.accuracy_score(Y, Y_pred),3))\nmetrics.roc_curve(Y, Y_pred)\nprint(metrics.roc_auc_score(Y, Y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#free up ram\ndel df1, df_label, cm\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#run prediction on test data\n\nprint(len(keep))\n#need to only load some columns due to ram limitations\ndf2=pd.read_parquet('/kaggle/input/amex-parquet/test_data.parquet', columns =keep)\nprint(df2.shape)\n\n#hot ones\ndf2 = pd.get_dummies(df2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Handling missing values via imputation\n#df2.iloc[:,:] = my_imputer.fit_transform(df2.iloc[:,:])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#using only most recent transaction from each customer\ntemp = df2.shape\ndf2=df2.set_index(['customer_ID'])\ndf2=df2.ffill()\ndf2=df2.bfill()\ndf2=df2.reset_index()\n\ndf2=df2.groupby('customer_ID').tail(1)\ndf2=df2.set_index(['customer_ID'])\n\n#Drop date column since it is no longer useful\ndf2.drop(['S_2'],axis=1,inplace=True)\n\nprint(temp, df2.shape)\n\n#inspecting NaN\nfor i in range(len(df2.columns)):\n    print('Columns left with NaN:')\n    if (df2.iloc[:,i].isnull().sum()/len(df2) > 0):\n        print(df2.columns[i], round(df2.iloc[:,i].isnull().sum()/len(df2),2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df2.iloc[:, :].values.reshape(-1, len(df2.columns))\nY_pred2 = log.predict(X)\nprint(Y_pred2)\n\ndf2 = df2.reset_index()\n\nfinal = pd.DatFrame({\"customer_ID\":df2.customer_ID,\"prediction\":Y_pred2})\n\nprint(Y_pred2, np.sum(Y_pred2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}