{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Our goal is to use this industrial scale dataset to predict if a customer will default in the future. We aim to put together a quick and rough solution.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.impute import SimpleImputer\nfrom sklearn import metrics\nimport gc\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-08-26T04:04:11.545874Z","iopub.execute_input":"2022-08-26T04:04:11.546390Z","iopub.status.idle":"2022-08-26T04:04:12.453685Z","shell.execute_reply.started":"2022-08-26T04:04:11.546286Z","shell.execute_reply":"2022-08-26T04:04:12.452737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This data set is too large to be loaded as a csv file. We convert the data from csv to parquet and then load the parquet format into a pandas dataframe. \n\nNext, we take a preview of our data.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\ndf=pd.read_parquet('/kaggle/input/amex-parquet/train_data.parquet')\nprint(df.head)","metadata":{"execution":{"iopub.status.busy":"2022-08-31T22:50:19.754182Z","iopub.execute_input":"2022-08-31T22:50:19.754924Z","iopub.status.idle":"2022-08-31T22:51:08.669484Z","shell.execute_reply.started":"2022-08-31T22:50:19.754823Z","shell.execute_reply":"2022-08-31T22:51:08.667188Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"<bound method NDFrame.head of                                                customer_ID         S_2  \\\n0        0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  2017-03-09   \n1        0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  2017-04-07   \n2        0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  2017-05-28   \n3        0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  2017-06-13   \n4        0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  2017-07-16   \n...                                                    ...         ...   \n5531446  fffff1d38b785cef84adeace64f8f83db3a0c31e8d92ea...  2017-11-05   \n5531447  fffff1d38b785cef84adeace64f8f83db3a0c31e8d92ea...  2017-12-23   \n5531448  fffff1d38b785cef84adeace64f8f83db3a0c31e8d92ea...  2018-01-06   \n5531449  fffff1d38b785cef84adeace64f8f83db3a0c31e8d92ea...  2018-02-06   \n5531450  fffff1d38b785cef84adeace64f8f83db3a0c31e8d92ea...  2018-03-14   \n\n              P_2      D_39       B_1       B_2       R_1       S_3      D_41  \\\n0        0.938469  0.001733  0.008724  1.006838  0.009228  0.124035  0.008771   \n1        0.936665  0.005775  0.004923  1.000653  0.006151  0.126750  0.000798   \n2        0.954180  0.091505  0.021655  1.009672  0.006815  0.123977  0.007598   \n3        0.960384  0.002455  0.013683  1.002700  0.001373  0.117169  0.000685   \n4        0.947248  0.002483  0.015193  1.000727  0.007605  0.117325  0.004653   \n...           ...       ...       ...       ...       ...       ...       ...   \n5531446  0.979333  0.416013  0.020818  0.828199  0.003487  0.090743  0.005340   \n5531447  0.984907  0.296536  0.007209  0.812610  0.005904  0.079886  0.002243   \n5531448  0.983019  0.443984  0.013151  0.815422  0.003457  0.100503  0.002111   \n5531449  0.969861  0.442553  0.009855  1.003541  0.005117  0.101802  0.009930   \n5531450  0.982175  0.002474  0.000077  0.992880  0.000809  0.119165  0.003287   \n\n              B_3  ...  D_137  D_138     D_139     D_140     D_141  D_142  \\\n0        0.004709  ...    NaN    NaN  0.002427  0.003706  0.003818    NaN   \n1        0.002714  ...    NaN    NaN  0.003954  0.003167  0.005032    NaN   \n2        0.009423  ...    NaN    NaN  0.003269  0.007329  0.000427    NaN   \n3        0.005531  ...    NaN    NaN  0.006117  0.004516  0.003200    NaN   \n4        0.009312  ...    NaN    NaN  0.003671  0.004946  0.008889    NaN   \n...           ...  ...    ...    ...       ...       ...       ...    ...   \n5531446  0.025139  ...    NaN    NaN  0.006838  0.003680  0.000457    NaN   \n5531447  0.023691  ...    NaN    NaN  0.003310  0.007097  0.007857    NaN   \n5531448  0.012343  ...    NaN    NaN  0.009955  0.009994  0.001088    NaN   \n5531449  0.008578  ...    NaN    NaN  0.005541  0.006564  0.009883    NaN   \n5531450  0.014092  ...    NaN    NaN  0.007316  0.002888  0.006207    NaN   \n\n            D_143     D_144     D_145  target  \n0        0.000569  0.000610  0.002674       0  \n1        0.009576  0.005492  0.009217       0  \n2        0.003429  0.006986  0.002603       0  \n3        0.008419  0.006527  0.009600       0  \n4        0.001670  0.008126  0.009827       0  \n...           ...       ...       ...     ...  \n5531446  0.000905  0.001498  0.002774       0  \n5531447  0.002777  0.008225  0.008856       0  \n5531448  0.005693  0.006773  0.005566       0  \n5531449  0.008123  0.001168  0.003983       0  \n5531450  0.005110  0.003184  0.001914       0  \n\n[5531451 rows x 191 columns]>\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Due to hardware limitations we will need to reduce the size of our data. We note the customer ID and the date columns. \n\nLets separate our labels from our dataset.","metadata":{}},{"cell_type":"code","source":"print(len(df.columns))\ndf_label = df.iloc[:,len(df.columns)-1]\ndf = df.iloc[:,0:len(df.columns)-1]\nprint(df_label.sum()/len(df_label))","metadata":{"execution":{"iopub.status.busy":"2022-08-31T22:53:07.376525Z","iopub.execute_input":"2022-08-31T22:53:07.377028Z","iopub.status.idle":"2022-08-31T22:53:11.311967Z","shell.execute_reply.started":"2022-08-31T22:53:07.376992Z","shell.execute_reply":"2022-08-31T22:53:11.310193Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"190\n0.06119057300697412\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Our train data contains % positive cases.\n\nNow lets take a look at our data types.","metadata":{}},{"cell_type":"code","source":"print(df.dtypes.value_counts())","metadata":{"execution":{"iopub.status.busy":"2022-08-31T22:44:12.092985Z","iopub.execute_input":"2022-08-31T22:44:12.093775Z","iopub.status.idle":"2022-08-31T22:44:12.311743Z","shell.execute_reply.started":"2022-08-31T22:44:12.093678Z","shell.execute_reply":"2022-08-31T22:44:12.310037Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"float32    185\nobject       4\nint64        1\ndtype: int64\n","output_type":"stream"}]},{"cell_type":"markdown","source":"There are four non-numeric data types. Let's convert these so we may apply a logistic regression model.\n\nLet's plot our columns.","metadata":{}},{"cell_type":"code","source":"#hist = df1.hist(bins=10, figsize = (40,200), layout=(-1,4) )","metadata":{"execution":{"iopub.status.busy":"2022-08-31T23:01:02.596230Z","iopub.execute_input":"2022-08-31T23:01:02.597629Z","iopub.status.idle":"2022-08-31T23:01:02.605282Z","shell.execute_reply.started":"2022-08-31T23:01:02.597566Z","shell.execute_reply":"2022-08-31T23:01:02.603708Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"Let's find the columns with a significant amount of NaN values. ","metadata":{}},{"cell_type":"code","source":"temp = [column for column in df.columns if df[column].isnull().sum()/len(df) >= 0.9]\nprint(len(temp))\n\n#drop columns with high freq of NaN\ndf.drop(temp, axis=1, inplace=True)\n\nprint( len(df.columns) )","metadata":{"execution":{"iopub.status.busy":"2022-08-30T14:30:23.971726Z","iopub.execute_input":"2022-08-30T14:30:23.972153Z","iopub.status.idle":"2022-08-30T14:30:28.848853Z","shell.execute_reply.started":"2022-08-30T14:30:23.972120Z","shell.execute_reply":"2022-08-30T14:30:28.847519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#using only most recent transaction from each customer\ntemp = df.shape\ndf=df.set_index(['customer_ID'])\ndf=df.ffill()\ndf=df.bfill()\ndf=df.reset_index()\n\ndf=df.groupby('customer_ID').tail(1)\ndf=df.set_index(['customer_ID'])\n\n#Drop date column since it is no longer useful\ndf.drop(['S_2'],axis=1,inplace=True)\n\nprint(temp, df.shape)\n\n#inspecting NaN\nprint('Columns left with NaN:')\ntemp = [column for column in df.columns if df[column].isnull().sum()/len(df) >0]\nprint(len(temp))","metadata":{"execution":{"iopub.status.busy":"2022-08-25T01:07:32.321765Z","iopub.execute_input":"2022-08-25T01:07:32.322189Z","iopub.status.idle":"2022-08-25T01:07:55.300441Z","shell.execute_reply.started":"2022-08-25T01:07:32.322100Z","shell.execute_reply":"2022-08-25T01:07:55.299237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df.head)\nkeep = df.columns","metadata":{"execution":{"iopub.status.busy":"2022-08-31T23:02:38.013693Z","iopub.execute_input":"2022-08-31T23:02:38.014264Z","iopub.status.idle":"2022-08-31T23:02:39.693982Z","shell.execute_reply.started":"2022-08-31T23:02:38.014216Z","shell.execute_reply":"2022-08-31T23:02:39.692249Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"<bound method NDFrame.head of                                                customer_ID         S_2  \\\n0        0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  2017-03-09   \n1        0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  2017-04-07   \n2        0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  2017-05-28   \n3        0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  2017-06-13   \n4        0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  2017-07-16   \n...                                                    ...         ...   \n5531446  fffff1d38b785cef84adeace64f8f83db3a0c31e8d92ea...  2017-11-05   \n5531447  fffff1d38b785cef84adeace64f8f83db3a0c31e8d92ea...  2017-12-23   \n5531448  fffff1d38b785cef84adeace64f8f83db3a0c31e8d92ea...  2018-01-06   \n5531449  fffff1d38b785cef84adeace64f8f83db3a0c31e8d92ea...  2018-02-06   \n5531450  fffff1d38b785cef84adeace64f8f83db3a0c31e8d92ea...  2018-03-14   \n\n              P_2      D_39       B_1       B_2       R_1       S_3      D_41  \\\n0        0.938469  0.001733  0.008724  1.006838  0.009228  0.124035  0.008771   \n1        0.936665  0.005775  0.004923  1.000653  0.006151  0.126750  0.000798   \n2        0.954180  0.091505  0.021655  1.009672  0.006815  0.123977  0.007598   \n3        0.960384  0.002455  0.013683  1.002700  0.001373  0.117169  0.000685   \n4        0.947248  0.002483  0.015193  1.000727  0.007605  0.117325  0.004653   \n...           ...       ...       ...       ...       ...       ...       ...   \n5531446  0.979333  0.416013  0.020818  0.828199  0.003487  0.090743  0.005340   \n5531447  0.984907  0.296536  0.007209  0.812610  0.005904  0.079886  0.002243   \n5531448  0.983019  0.443984  0.013151  0.815422  0.003457  0.100503  0.002111   \n5531449  0.969861  0.442553  0.009855  1.003541  0.005117  0.101802  0.009930   \n5531450  0.982175  0.002474  0.000077  0.992880  0.000809  0.119165  0.003287   \n\n              B_3  ...  D_135  D_136  D_137  D_138     D_139     D_140  \\\n0        0.004709  ...    NaN    NaN    NaN    NaN  0.002427  0.003706   \n1        0.002714  ...    NaN    NaN    NaN    NaN  0.003954  0.003167   \n2        0.009423  ...    NaN    NaN    NaN    NaN  0.003269  0.007329   \n3        0.005531  ...    NaN    NaN    NaN    NaN  0.006117  0.004516   \n4        0.009312  ...    NaN    NaN    NaN    NaN  0.003671  0.004946   \n...           ...  ...    ...    ...    ...    ...       ...       ...   \n5531446  0.025139  ...    NaN    NaN    NaN    NaN  0.006838  0.003680   \n5531447  0.023691  ...    NaN    NaN    NaN    NaN  0.003310  0.007097   \n5531448  0.012343  ...    NaN    NaN    NaN    NaN  0.009955  0.009994   \n5531449  0.008578  ...    NaN    NaN    NaN    NaN  0.005541  0.006564   \n5531450  0.014092  ...    NaN    NaN    NaN    NaN  0.007316  0.002888   \n\n            D_141  D_142     D_143     D_144  \n0        0.003818    NaN  0.000569  0.000610  \n1        0.005032    NaN  0.009576  0.005492  \n2        0.000427    NaN  0.003429  0.006986  \n3        0.003200    NaN  0.008419  0.006527  \n4        0.008889    NaN  0.001670  0.008126  \n...           ...    ...       ...       ...  \n5531446  0.000457    NaN  0.000905  0.001498  \n5531447  0.007857    NaN  0.002777  0.008225  \n5531448  0.001088    NaN  0.005693  0.006773  \n5531449  0.009883    NaN  0.008123  0.001168  \n5531450  0.006207    NaN  0.005110  0.003184  \n\n[5531451 rows x 189 columns]>\n","output_type":"stream"}]},{"cell_type":"markdown","source":"We aim to remove data columns that have too high a correlation as logistic regression requires it.","metadata":{}},{"cell_type":"code","source":"print(df.shape)\n# Create correlation matrix\ncorr_matrix = df.corr().abs()\n\n# Select upper triangle of correlation matrix\nupper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n\n# Find features with correlation greater than 0.9\nto_drop = [column for column in upper.columns if any(upper[column] > 0.9)]\n\n# Drop features w/ high correl\ndf.drop(to_drop, axis=1, inplace=True)\n\nprint(df.shape)","metadata":{"execution":{"iopub.status.busy":"2022-08-31T23:04:10.122145Z","iopub.execute_input":"2022-08-31T23:04:10.122707Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"(5531451, 189)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"To further reduce the degrees of freedom we remove columns with low variance","metadata":{}},{"cell_type":"code","source":"#Removing low variance columns in interest of ram\nfrom sklearn.feature_selection import VarianceThreshold\nfrom itertools import compress\n\ntemp = df.drop(['D_63', 'D_64'], axis=1)\n\n# Initialize and fit the method\nvt = VarianceThreshold(threshold = float(0.1))\nvt.fit(temp)\n\n#columns with sufficient variance\nkeep = list(compress(temp.columns, vt.get_support()))\n\nkeep.append('D_63')\nkeep.append('D_64')\n\ndf=df[keep]\n\nkeep.append('customer_ID')\nkeep.append('S_2')\nlen(keep)","metadata":{"execution":{"iopub.status.busy":"2022-08-25T01:08:21.393652Z","iopub.execute_input":"2022-08-25T01:08:21.394059Z","iopub.status.idle":"2022-08-25T01:08:22.048748Z","shell.execute_reply.started":"2022-08-25T01:08:21.394022Z","shell.execute_reply":"2022-08-25T01:08:22.047171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\"\n#removing outliers\nprint(df1.shape)\n\ndf1 = df1[df1['R_6'] < df1['R_6'].quantile(0.97)]\nprint(df1['R_6'].max())\nprint(df1.shape)\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-08-25T01:08:22.049996Z","iopub.execute_input":"2022-08-25T01:08:22.050412Z","iopub.status.idle":"2022-08-25T01:08:22.058502Z","shell.execute_reply.started":"2022-08-25T01:08:22.050384Z","shell.execute_reply":"2022-08-25T01:08:22.057056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"#df1.iloc[:100000,7].value_counts()\nprint(df1.iloc[:,1].head())\n\n\n#What type of variable for dates\ndf1['S_2'] = pd.to_datetime(df1['S_2'])\ndf1['S_2'] = pd.to_numeric(df1['S_2'])\n\n#normalizing\n#df1['S_2'] = (df1['S_2']-df1['S_2'].min())/(df1['S_2'].max() - df1['S_2'].min())\nprint(df1['S_2'].head())\n\ndf1['S_2'] = pd.to_timedelta(df1['S_2'])\nprint(df1.iloc[:,1].dt.total_seconds())\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-08-25T01:08:22.060254Z","iopub.execute_input":"2022-08-25T01:08:22.061184Z","iopub.status.idle":"2022-08-25T01:08:22.072528Z","shell.execute_reply.started":"2022-08-25T01:08:22.061144Z","shell.execute_reply":"2022-08-25T01:08:22.071748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Finally we convert our object columns to numeric via hot ones","metadata":{}},{"cell_type":"code","source":"#Hot ones\ndf1 = pd.get_dummies(df1)\nprint(df1.shape)\nprint(df1.columns)\nprint(df1['D_64_-1'].sum())\ndf1.drop(['D_64_-1'], axis=1, inplace = True)\nprint(df1.shape)","metadata":{"execution":{"iopub.status.busy":"2022-08-25T01:08:22.073870Z","iopub.execute_input":"2022-08-25T01:08:22.074284Z","iopub.status.idle":"2022-08-25T01:08:22.350779Z","shell.execute_reply.started":"2022-08-25T01:08:22.074257Z","shell.execute_reply":"2022-08-25T01:08:22.349089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Handling missing values\n#my_imputer = SimpleImputer()\n#df1.iloc[:,:] = my_imputer.fit_transform(df1.iloc[:,:])","metadata":{"execution":{"iopub.status.busy":"2022-08-25T01:08:22.352261Z","iopub.execute_input":"2022-08-25T01:08:22.352600Z","iopub.status.idle":"2022-08-25T01:08:22.357375Z","shell.execute_reply.started":"2022-08-25T01:08:22.352529Z","shell.execute_reply":"2022-08-25T01:08:22.356465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df1.iloc[:, :].values.reshape(-1, len(df1.columns))\nY = df_label.iloc[:len(df1), 1].values.reshape(-1, 1)","metadata":{"execution":{"iopub.status.busy":"2022-08-25T01:08:22.358725Z","iopub.execute_input":"2022-08-25T01:08:22.359192Z","iopub.status.idle":"2022-08-25T01:08:22.395071Z","shell.execute_reply.started":"2022-08-25T01:08:22.359164Z","shell.execute_reply":"2022-08-25T01:08:22.393272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\n# create object for the class\nlog = LogisticRegression()\nlog.fit(X, Y) \nY_pred = log.predict(X)\n\nprint(Y_pred, np.sum(Y_pred))\nprint(log.score(X, Y))\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-08-25T01:08:22.397013Z","iopub.execute_input":"2022-08-25T01:08:22.398335Z","iopub.status.idle":"2022-08-25T01:08:22.406449Z","shell.execute_reply.started":"2022-08-25T01:08:22.398293Z","shell.execute_reply":"2022-08-25T01:08:22.405143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#trying random forest\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\nmax_depth.append(None)\n# Minimum number of samples required to split a node\nmin_samples_split = [2, 5, 10]\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 4]\n# Method of selecting samples for training each tree\nbootstrap = [True, False]\n# Create the random grid\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap}\n\nmodel = RandomForestClassifier(n_estimators=400, max_features='sqrt', bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_jobs=-1)\n#rf_random = GridSearchCV(estimator = rf, param_grid = random_grid, cv = 3, verbose=1, n_jobs = -1)\n# Fit the random search model\nmodel.fit(X,Y)","metadata":{"execution":{"iopub.status.busy":"2022-08-25T01:08:22.408382Z","iopub.execute_input":"2022-08-25T01:08:22.409883Z","iopub.status.idle":"2022-08-25T01:08:33.831520Z","shell.execute_reply.started":"2022-08-25T01:08:22.409847Z","shell.execute_reply":"2022-08-25T01:08:33.829174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_pred = model.predict_proba(X)\nY_pred = Y_pred[:,1]\nprint(Y_pred.shape, Y_pred[25:50])","metadata":{"execution":{"iopub.status.busy":"2022-08-25T01:08:33.834076Z","iopub.execute_input":"2022-08-25T01:08:33.834494Z","iopub.status.idle":"2022-08-25T01:08:34.165656Z","shell.execute_reply.started":"2022-08-25T01:08:33.834462Z","shell.execute_reply":"2022-08-25T01:08:34.164677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"from xgboost import XGBClassifier\nfrom sklearn.model_selection import RandomizedSearchCV\n\nparam_random_gb = {'learning_rate': np.arange(0.05,0.55, 0.1), 'n_estimators' : [125,150,175], 'subsample' : np.arange(0.3,1.0, 0.1), 'max_depth':[3,4,5]}\n\nmse_random = RandomizedSearchCV(estimator = XGBClassifier(), param_distributions = param_random_gb, n_iter = 10,scoring = 'neg_mean_squared_error', cv = 4, verbose = 1)\n\n\n\nmse_random.best_params_={'subsample': 0.5, 'n_estimators': 175, 'max_depth': 3, 'learning_rate': 0.15}\nmse_random.best_score_ = (0.32263831733224874)**2\n\nmse_random.fit(X,Y)\n\n#Run XGBoost model with the best parameters found\nmodel=XGBClassifier(n_estimators=200,max_depth=3,learning_rate=0.15, subsample=0.5)\nmodel.fit(x_train_split,y_train_split)\n#Test the model\ny_predict=model.predict(x_test_split)\nprint('XGBoost Classifier Accuracy: {:.3f}'.format(accuracy_score(y_test_split, y_predict)))\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-08-25T01:08:34.166742Z","iopub.execute_input":"2022-08-25T01:08:34.167113Z","iopub.status.idle":"2022-08-25T01:08:34.175661Z","shell.execute_reply.started":"2022-08-25T01:08:34.167074Z","shell.execute_reply":"2022-08-25T01:08:34.173894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"def evaluate(model, test_features, test_labels):\n    predictions = model.predict(test_features)\n    errors = abs(predictions - test_labels)\n    mape = 100 * np.mean(errors / test_labels)\n    accuracy = 100 - mape\n    print('Model Performance')\n    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n    print('Accuracy = {:0.2f}%.'.format(accuracy))\n    \naccuracy = evaluate(model, X, Y)\n\nprint('Accuracy:{:0.2f}%.'.format( 100 * accuracy))\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-08-25T01:08:34.176922Z","iopub.execute_input":"2022-08-25T01:08:34.177821Z","iopub.status.idle":"2022-08-25T01:08:34.193714Z","shell.execute_reply.started":"2022-08-25T01:08:34.177791Z","shell.execute_reply":"2022-08-25T01:08:34.192516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\"cm = metrics.confusion_matrix(Y, Y_pred)\n\nplt.figure(figsize=(9,9))\nsns.heatmap(cm, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'YlGnBu');\nplt.ylabel('Actual label');\nplt.xlabel('Predicted label');\nall_sample_title = 'Accuracy Score: {0}'.format(round(log.score(X, Y),3))\nplt.title(all_sample_title, size = 15);\n\nprint('Accuracy:',round(metrics.accuracy_score(Y, Y_pred),3))\nmetrics.roc_curve(Y, Y_pred)\nprint(metrics.roc_auc_score(Y, Y_pred))\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-08-25T01:08:34.195851Z","iopub.execute_input":"2022-08-25T01:08:34.196221Z","iopub.status.idle":"2022-08-25T01:08:34.207518Z","shell.execute_reply.started":"2022-08-25T01:08:34.196194Z","shell.execute_reply":"2022-08-25T01:08:34.206106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#free up ram\ndel df1, df_label\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-08-25T01:08:34.208720Z","iopub.execute_input":"2022-08-25T01:08:34.209093Z","iopub.status.idle":"2022-08-25T01:08:34.368641Z","shell.execute_reply.started":"2022-08-25T01:08:34.209064Z","shell.execute_reply":"2022-08-25T01:08:34.366853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#run prediction on test data\n\nprint(len(keep))\n#need to only load some columns due to ram limitations\ndf2=pd.read_parquet('/kaggle/input/amex-parquet/test_data.parquet', columns =keep)\nprint(df2.shape)","metadata":{"execution":{"iopub.status.busy":"2022-08-25T01:08:34.370331Z","iopub.execute_input":"2022-08-25T01:08:34.370691Z","iopub.status.idle":"2022-08-25T01:08:57.463575Z","shell.execute_reply.started":"2022-08-25T01:08:34.370662Z","shell.execute_reply":"2022-08-25T01:08:57.462588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-25T01:08:57.465017Z","iopub.execute_input":"2022-08-25T01:08:57.465352Z","iopub.status.idle":"2022-08-25T01:08:57.492478Z","shell.execute_reply.started":"2022-08-25T01:08:57.465320Z","shell.execute_reply":"2022-08-25T01:08:57.491161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Handling missing values via imputation\n#df2.iloc[:,:] = my_imputer.fit_transform(df2.iloc[:,:])","metadata":{"execution":{"iopub.status.busy":"2022-08-25T01:08:57.494258Z","iopub.execute_input":"2022-08-25T01:08:57.495872Z","iopub.status.idle":"2022-08-25T01:08:57.503240Z","shell.execute_reply.started":"2022-08-25T01:08:57.495806Z","shell.execute_reply":"2022-08-25T01:08:57.502174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#using only most recent transaction from each customer\n#Does this make sense for test data??\ntemp = df2.shape\ndf2=df2.set_index(['customer_ID'])\ndf2=df2.ffill()\ndf2=df2.bfill()\ndf2=df2.reset_index()\n\ndf2=df2.groupby('customer_ID').tail(1)\ndf2=df2.set_index(['customer_ID'])\n\n#Drop date column since it is no longer useful\ndf2.drop(['S_2'],axis=1,inplace=True)\n\nprint(temp, df2.shape)\n\n#inspecting NaN\nprint('Columns left with NaN:')\nfor i in range(len(df2.columns)):\n    if (df2.iloc[:,i].isnull().sum()/len(df2) > 0):\n        print(df2.columns[i], round(df2.iloc[:,i].isnull().sum()/len(df2),2))","metadata":{"execution":{"iopub.status.busy":"2022-08-25T01:08:57.504381Z","iopub.execute_input":"2022-08-25T01:08:57.504710Z","iopub.status.idle":"2022-08-25T01:09:03.261126Z","shell.execute_reply.started":"2022-08-25T01:08:57.504684Z","shell.execute_reply":"2022-08-25T01:09:03.259912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#hot ones\ndf2 = pd.get_dummies(df2)\nprint(df2.shape)\nprint(df2.columns)","metadata":{"execution":{"iopub.status.busy":"2022-08-25T01:09:03.265162Z","iopub.execute_input":"2022-08-25T01:09:03.266666Z","iopub.status.idle":"2022-08-25T01:09:03.790609Z","shell.execute_reply.started":"2022-08-25T01:09:03.266521Z","shell.execute_reply":"2022-08-25T01:09:03.789269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-25T01:09:03.791995Z","iopub.execute_input":"2022-08-25T01:09:03.792333Z","iopub.status.idle":"2022-08-25T01:09:03.816310Z","shell.execute_reply.started":"2022-08-25T01:09:03.792307Z","shell.execute_reply":"2022-08-25T01:09:03.815012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df2.iloc[:, :].values.reshape(-1, len(df2.columns))","metadata":{"execution":{"iopub.status.busy":"2022-08-25T01:09:03.817631Z","iopub.execute_input":"2022-08-25T01:09:03.817914Z","iopub.status.idle":"2022-08-25T01:09:03.864362Z","shell.execute_reply.started":"2022-08-25T01:09:03.817888Z","shell.execute_reply":"2022-08-25T01:09:03.863129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"X = df2.iloc[:, :].values.reshape(-1, len(df2.columns))\n\nY_pred2 = log.predict(X)\nprint(Y_pred2)\n\ndf2 = df2.reset_index()\n\nfinal = pd.DataFrame({\"customer_ID\":df2.customer_ID,\"prediction\":Y_pred2})\n\nfinal.to_csv('submission.csv', index=False)\nprint(Y_pred2, np.sum(Y_pred2))\n\n#score ended as ~50\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-08-25T01:09:03.865758Z","iopub.execute_input":"2022-08-25T01:09:03.866166Z","iopub.status.idle":"2022-08-25T01:09:03.875220Z","shell.execute_reply.started":"2022-08-25T01:09:03.866110Z","shell.execute_reply":"2022-08-25T01:09:03.873080Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_pred2 = model.predict_proba(df2)\nY_pred2 = Y_pred2[:,1]\ndf2 = df2.reset_index()\nprint(Y_pred2, np.sum(Y_pred2))\nfinal = pd.DataFrame({\"customer_ID\":df2.customer_ID,\"prediction\":Y_pred2})\nprint(final)","metadata":{"execution":{"iopub.status.busy":"2022-08-25T01:09:03.876658Z","iopub.execute_input":"2022-08-25T01:09:03.876985Z","iopub.status.idle":"2022-08-25T01:09:04.523592Z","shell.execute_reply.started":"2022-08-25T01:09:03.876948Z","shell.execute_reply":"2022-08-25T01:09:04.521741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final.to_csv('submission.csv', index=False)\nprint(final)","metadata":{"execution":{"iopub.status.busy":"2022-08-25T01:09:04.524900Z","iopub.execute_input":"2022-08-25T01:09:04.525205Z","iopub.status.idle":"2022-08-25T01:09:07.392157Z","shell.execute_reply.started":"2022-08-25T01:09:04.525178Z","shell.execute_reply":"2022-08-25T01:09:07.390800Z"},"trusted":true},"execution_count":null,"outputs":[]}]}